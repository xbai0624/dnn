SaveTrainedWeightsAndBias(): Saving trained weights and bias from layer: 0 to files.
SaveTrainedWeightsAndBias(): Saving trained weights and bias from layer: 1 to files.
SaveTrainedWeightsAndBias(): Saving trained weights and bias from layer: 2 to files.
SaveTrainedWeightsAndBias(): Saving trained weights and bias from layer: 3 to files.
[------]Number of epoch: 0/50
......Info: 1 batches in this epoch
......... training for batch: 0/1
>>>: 200 samples in current batch.
----------------------------------------------------------
g_t: 
      -0.000191057        0.00122953        0.00221909        0.00202564       0.000171665       -0.00277453       -0.00160539      -0.000711721        0.00223934       -0.00192267       -0.00566567       -0.00500284        0.00343217        0.00422034        0.00307993       -0.00344573
       0.000191057       -0.00122953       -0.00221909       -0.00202564      -0.000171665        0.00277453        0.00160539       0.000711721       -0.00223934        0.00192267        0.00566567        0.00500284       -0.00343217       -0.00422034       -0.00307993        0.00344573

m_t_1: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

 1 - beta1: 0.1
m_tmp: 
      -1.91057e-05       0.000122953       0.000221909       0.000202564       1.71665e-05      -0.000277453       -0.00016054      -7.11721e-05       0.000223934      -0.000192267      -0.000566567      -0.000500284       0.000343217       0.000422034       0.000307993      -0.000344573
       1.91057e-05      -0.000122953      -0.000221909      -0.000202564      -1.71665e-05       0.000277453       0.000160539       7.11721e-05      -0.000223934       0.000192267       0.000566567       0.000500284      -0.000343217      -0.000422034      -0.000307993       0.000344573

m_t_1*beta1: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t: = (m_t_1 * beta1) + g_t * (1 - beta1): 
      -1.91057e-05       0.000122953       0.000221909       0.000202564       1.71665e-05      -0.000277453       -0.00016054      -7.11721e-05       0.000223934      -0.000192267      -0.000566567      -0.000500284       0.000343217       0.000422034       0.000307993      -0.000344573
       1.91057e-05      -0.000122953      -0.000221909      -0.000202564      -1.71665e-05       0.000277453       0.000160539       7.11721e-05      -0.000223934       0.000192267       0.000566567       0.000500284      -0.000343217      -0.000422034      -0.000307993       0.000344573

v_t_1: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

g_t^2 * (1. - beta2(0.999))
       3.65026e-11       1.51174e-09       4.92436e-09        4.1032e-09       2.94687e-11         7.698e-09       2.57729e-09       5.06547e-10       5.01463e-09       3.69665e-09       3.20998e-08       2.50285e-08       1.17798e-08       1.78113e-08       9.48598e-09       1.18731e-08
       3.65026e-11       1.51174e-09       4.92436e-09        4.1032e-09       2.94688e-11         7.698e-09       2.57729e-09       5.06547e-10       5.01463e-09       3.69665e-09       3.20999e-08       2.50285e-08       1.17798e-08       1.78113e-08       9.48598e-09       1.18731e-08

v_t_1 * beta2:
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

vt = v_t_1*beta2 + g_t^2*(1-beta2): 
       3.65026e-11       1.51174e-09       4.92436e-09        4.1032e-09       2.94687e-11         7.698e-09       2.57729e-09       5.06547e-10       5.01463e-09       3.69665e-09       3.20998e-08       2.50285e-08       1.17798e-08       1.78113e-08       9.48598e-09       1.18731e-08
       3.65026e-11       1.51174e-09       4.92436e-09        4.1032e-09       2.94688e-11         7.698e-09       2.57729e-09       5.06547e-10       5.01463e-09       3.69665e-09       3.20999e-08       2.50285e-08       1.17798e-08       1.78113e-08       9.48598e-09       1.18731e-08

bias corrected m_t: /0.1
      -0.000191057        0.00122953        0.00221909        0.00202564       0.000171665       -0.00277453        -0.0016054      -0.000711721        0.00223934       -0.00192267       -0.00566567       -0.00500284        0.00343217        0.00422034        0.00307993       -0.00344573
       0.000191057       -0.00122953       -0.00221909       -0.00202564      -0.000171665        0.00277453        0.00160539       0.000711721       -0.00223934        0.00192267        0.00566567        0.00500284       -0.00343217       -0.00422034       -0.00307993        0.00344573

bias corrected v_t: /0.001
       3.65026e-08       1.51174e-06       4.92436e-06        4.1032e-06       2.94687e-08         7.698e-06       2.57729e-06       5.06547e-07       5.01463e-06       3.69665e-06       3.20998e-05       2.50285e-05       1.17798e-05       1.78113e-05       9.48598e-06       1.18731e-05
       3.65026e-08       1.51174e-06       4.92436e-06        4.1032e-06       2.94687e-08         7.698e-06       2.57729e-06       5.06547e-07       5.01463e-06       3.69665e-06       3.20999e-05       2.50285e-05       1.17798e-05       1.78113e-05       9.48598e-06       1.18731e-05

sqrt(^v_t): 
       0.000191057        0.00122953        0.00221909        0.00202564       0.000171665        0.00277453        0.00160539       0.000711721        0.00223934        0.00192267        0.00566567        0.00500284        0.00343217        0.00422034        0.00307993        0.00344573
       0.000191057        0.00122953        0.00221909        0.00202564       0.000171665        0.00277453        0.00160539       0.000711721        0.00223934        0.00192267        0.00566567        0.00500284        0.00343217        0.00422034        0.00307993        0.00344573

m_epsilon: 
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08

sqrt(^v_t): + epsilon
       0.000191067        0.00122954         0.0022191        0.00202565       0.000171675        0.00277454        0.00160541       0.000711731        0.00223935        0.00192268        0.00566568        0.00500285        0.00343218        0.00422035        0.00307994        0.00344574
       0.000191067        0.00122954         0.0022191        0.00202565       0.000171675        0.00277454         0.0016054       0.000711731        0.00223935        0.00192268        0.00566568        0.00500285        0.00343218        0.00422035        0.00307994        0.00344574

^m_t/(sqrt(^v_t) + epsilon):
         -0.999948          0.999992          0.999995          0.999995          0.999942         -0.999996         -0.999994         -0.999986          0.999996         -0.999995         -0.999998         -0.999998          0.999997          0.999998          0.999997         -0.999997
          0.999948         -0.999992         -0.999995         -0.999995         -0.999942          0.999996          0.999994          0.999986         -0.999996          0.999995          0.999998          0.999998         -0.999997         -0.999998         -0.999997          0.999997

learning rate: 0.9
dw_Adam: 
         -0.899953          0.899993          0.899996          0.899996          0.899948         -0.899997         -0.899994         -0.899987          0.899996         -0.899995         -0.899998         -0.899998          0.899997          0.899998          0.899997         -0.899997
          0.899953         -0.899993         -0.899996         -0.899996         -0.899948          0.899997          0.899994          0.899987         -0.899996          0.899995          0.899998          0.899998         -0.899997         -0.899998         -0.899997          0.899997

        batch training cost: 793 milliseconds
............ accuracy for batch training: 0
............    losss for batch training: 1.38566
[------]Number of epoch: 1/50
......Info: 1 batches in this epoch
......... training for batch: 0/1
>>>: 200 samples in current batch.
----------------------------------------------------------
g_t: 
       0.000880388        0.00161794        0.00112591       0.000933179        0.00117072      -0.000564766        -0.0013805       -0.00135735         0.0015231      -0.000568345       -0.00383144       -0.00268253          0.001821        0.00250717        0.00142006       -0.00104461
      -0.000880388       -0.00161794       -0.00112591      -0.000933179       -0.00117072       0.000564766         0.0013805        0.00135735        -0.0015231       0.000568345        0.00383144        0.00268253         -0.001821       -0.00250717       -0.00142006        0.00104461

m_t_1: 
      -1.91057e-05       0.000122953       0.000221909       0.000202564       1.71665e-05      -0.000277453       -0.00016054      -7.11721e-05       0.000223934      -0.000192267      -0.000566567      -0.000500284       0.000343217       0.000422034       0.000307993      -0.000344573
       1.91057e-05      -0.000122953      -0.000221909      -0.000202564      -1.71665e-05       0.000277453       0.000160539       7.11721e-05      -0.000223934       0.000192267       0.000566567       0.000500284      -0.000343217      -0.000422034      -0.000307993       0.000344573

 1 - beta1: 0.1
m_tmp: 
       8.80388e-05       0.000161794       0.000112591       9.33179e-05       0.000117072      -5.64766e-05       -0.00013805      -0.000135735        0.00015231      -5.68345e-05      -0.000383144      -0.000268253         0.0001821       0.000250717       0.000142006      -0.000104461
      -8.80388e-05      -0.000161794      -0.000112591      -9.33179e-05      -0.000117072       5.64766e-05        0.00013805       0.000135735       -0.00015231       5.68345e-05       0.000383144       0.000268253        -0.0001821      -0.000250717      -0.000142006       0.000104461

m_t_1*beta1: 
      -1.71951e-05       0.000110658       0.000199718       0.000182307       1.54498e-05      -0.000249707      -0.000144486      -6.40549e-05        0.00020154       -0.00017304      -0.000509911      -0.000450256       0.000308895       0.000379831       0.000277194      -0.000310116
       1.71951e-05      -0.000110658      -0.000199718      -0.000182307      -1.54498e-05       0.000249707       0.000144486       6.40549e-05       -0.00020154        0.00017304       0.000509911       0.000450256      -0.000308895      -0.000379831      -0.000277194       0.000310116

m_t: = (m_t_1 * beta1) + g_t * (1 - beta1): 
       7.08437e-05       0.000272452       0.000312309       0.000275625       0.000132522      -0.000306184      -0.000282535      -0.000199789        0.00035385      -0.000229875      -0.000893055      -0.000718509       0.000490995       0.000630547         0.0004192      -0.000414577
      -7.08437e-05      -0.000272452      -0.000312309      -0.000275625      -0.000132522       0.000306184       0.000282535        0.00019979       -0.00035385       0.000229875       0.000893055       0.000718509      -0.000490995      -0.000630548        -0.0004192       0.000414577

v_t_1: 
       3.65026e-11       1.51174e-09       4.92436e-09        4.1032e-09       2.94687e-11         7.698e-09       2.57729e-09       5.06547e-10       5.01463e-09       3.69665e-09       3.20998e-08       2.50285e-08       1.17798e-08       1.78113e-08       9.48598e-09       1.18731e-08
       3.65026e-11       1.51174e-09       4.92436e-09        4.1032e-09       2.94688e-11         7.698e-09       2.57729e-09       5.06547e-10       5.01463e-09       3.69665e-09       3.20999e-08       2.50285e-08       1.17798e-08       1.78113e-08       9.48598e-09       1.18731e-08

g_t^2 * (1. - beta2(0.999))
       7.75082e-10       2.61773e-09       1.26767e-09       8.70823e-10       1.37058e-09        3.1896e-10       1.90577e-09       1.84239e-09       2.31982e-09       3.23016e-10       1.46799e-08       7.19596e-09       3.31604e-09       6.28589e-09       2.01658e-09       1.09122e-09
       7.75082e-10       2.61773e-09       1.26767e-09       8.70823e-10       1.37058e-09       3.18961e-10       1.90577e-09       1.84239e-09       2.31982e-09       3.23016e-10       1.46799e-08       7.19596e-09       3.31604e-09       6.28589e-09       2.01658e-09       1.09122e-09

v_t_1 * beta2:
       3.64661e-11       1.51023e-09       4.91944e-09        4.0991e-09       2.94392e-11        7.6903e-09       2.57472e-09       5.06041e-10       5.00962e-09       3.69295e-09       3.20677e-08       2.50034e-08        1.1768e-08       1.77935e-08        9.4765e-09       1.18612e-08
       3.64661e-11       1.51023e-09       4.91944e-09        4.0991e-09       2.94393e-11        7.6903e-09       2.57471e-09       5.06041e-10       5.00961e-09       3.69295e-09       3.20678e-08       2.50034e-08        1.1768e-08       1.77935e-08       9.47649e-09       1.18612e-08

vt = v_t_1*beta2 + g_t^2*(1-beta2): 
       8.11548e-10       4.12796e-09        6.1871e-09       4.96992e-09       1.40002e-09       8.00926e-09       4.48048e-09       2.34843e-09       7.32943e-09       4.01597e-09       4.67477e-08       3.21994e-08       1.50841e-08       2.40794e-08       1.14931e-08       1.29524e-08
       8.11548e-10       4.12796e-09       6.18711e-09       4.96992e-09       1.40002e-09       8.00926e-09       4.48048e-09       2.34843e-09       7.32943e-09       4.01597e-09       4.67477e-08       3.21994e-08       1.50841e-08       2.40794e-08       1.14931e-08       1.29524e-08

bias corrected m_t: /0.19
       0.000372861        0.00143396        0.00164373        0.00145066       0.000697483       -0.00161149       -0.00148703       -0.00105152        0.00186237       -0.00120987       -0.00470029       -0.00378163        0.00258419        0.00331867        0.00220632       -0.00218198
      -0.000372861       -0.00143396       -0.00164373       -0.00145066      -0.000697483        0.00161149        0.00148703        0.00105152       -0.00186237        0.00120987        0.00470029        0.00378163       -0.00258419       -0.00331867       -0.00220632        0.00218199

bias corrected v_t: /0.001999
       4.05977e-07       2.06501e-06        3.0951e-06        2.4862e-06       7.00361e-07       4.00663e-06       2.24136e-06        1.1748e-06       3.66655e-06       2.00899e-06       2.33855e-05       1.61077e-05        7.5458e-06       1.20457e-05       5.74941e-06       6.47944e-06
       4.05977e-07       2.06501e-06        3.0951e-06        2.4862e-06       7.00361e-07       4.00663e-06       2.24136e-06        1.1748e-06       3.66655e-06       2.00899e-06       2.33855e-05       1.61077e-05        7.5458e-06       1.20457e-05       5.74941e-06       6.47944e-06

sqrt(^v_t): 
       0.000637163        0.00143701        0.00175929        0.00157677       0.000836876        0.00200166        0.00149712        0.00108388        0.00191482        0.00141739        0.00483586        0.00401345        0.00274696        0.00347069        0.00239779        0.00254547
       0.000637163        0.00143701        0.00175929        0.00157677       0.000836876        0.00200166        0.00149712        0.00108388        0.00191482        0.00141739        0.00483586        0.00401345        0.00274696        0.00347069        0.00239779        0.00254547

m_epsilon: 
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08

sqrt(^v_t): + epsilon
       0.000637173        0.00143702         0.0017593        0.00157678       0.000836886        0.00200167        0.00149713        0.00108389        0.00191483         0.0014174        0.00483587        0.00401346        0.00274697         0.0034707         0.0023978        0.00254548
       0.000637173        0.00143702         0.0017593        0.00157678       0.000836886        0.00200167        0.00149713        0.00108389        0.00191483         0.0014174        0.00483587        0.00401346        0.00274697         0.0034707         0.0023978        0.00254548

^m_t/(sqrt(^v_t) + epsilon):
           0.58518          0.997864           0.93431          0.920013          0.833426         -0.805076         -0.993253         -0.970136            0.9726         -0.853583         -0.971963         -0.942237           0.94074          0.956196          0.920141         -0.857198
          -0.58518         -0.997864          -0.93431         -0.920013         -0.833426          0.805076          0.993253          0.970137           -0.9726          0.853583          0.971963          0.942237          -0.94074         -0.956196         -0.920141          0.857198

learning rate: 0.9
dw_Adam: 
          0.526662          0.898078          0.840879          0.828012          0.750084         -0.724568         -0.893928         -0.873123           0.87534         -0.768224         -0.874767         -0.848013          0.846666          0.860576          0.828127         -0.771478
         -0.526662         -0.898078         -0.840879         -0.828012         -0.750084          0.724568          0.893928          0.873123          -0.87534          0.768224          0.874767          0.848013         -0.846666         -0.860576         -0.828127          0.771478

        batch training cost: 398 milliseconds
............ accuracy for batch training: 0
............    losss for batch training: 1.29018
[------]Number of epoch: 2/50
......Info: 1 batches in this epoch
......... training for batch: 0/1
>>>: 200 samples in current batch.
----------------------------------------------------------
g_t: 
        -0.0270983        -0.0431984        -0.0599612        -0.0562866        -0.0155334        -0.0170482        -0.0347145        -0.0598683        -0.0339522        -0.0253567        -0.0272115         -0.042044        -0.0377983        -0.0387658        -0.0448429        -0.0438492
         0.0270983         0.0431984         0.0599612         0.0562865         0.0155334         0.0170482         0.0347145         0.0598683         0.0339522         0.0253567         0.0272115          0.042044         0.0377983         0.0387658         0.0448429         0.0438492

m_t_1: 
       7.08437e-05       0.000272452       0.000312309       0.000275625       0.000132522      -0.000306184      -0.000282535      -0.000199789        0.00035385      -0.000229875      -0.000893055      -0.000718509       0.000490995       0.000630547         0.0004192      -0.000414577
      -7.08437e-05      -0.000272452      -0.000312309      -0.000275625      -0.000132522       0.000306184       0.000282535        0.00019979       -0.00035385       0.000229875       0.000893055       0.000718509      -0.000490995      -0.000630548        -0.0004192       0.000414577

 1 - beta1: 0.1
m_tmp: 
       -0.00270983       -0.00431984       -0.00599612       -0.00562866       -0.00155334       -0.00170482       -0.00347145       -0.00598683       -0.00339522       -0.00253567       -0.00272115        -0.0042044       -0.00377983       -0.00387658       -0.00448429       -0.00438492
        0.00270983        0.00431984        0.00599612        0.00562865        0.00155334        0.00170482        0.00347145        0.00598683        0.00339522        0.00253567        0.00272115         0.0042044        0.00377983        0.00387658        0.00448429        0.00438492

m_t_1*beta1: 
       6.37593e-05       0.000245206       0.000281078       0.000248063        0.00011927      -0.000275566      -0.000254282      -0.000179811       0.000318465      -0.000206887      -0.000803749      -0.000646658       0.000441896       0.000567493        0.00037728      -0.000373119
      -6.37593e-05      -0.000245206      -0.000281078      -0.000248063       -0.00011927       0.000275566       0.000254282       0.000179811      -0.000318465       0.000206887       0.000803749       0.000646658      -0.000441896      -0.000567493       -0.00037728       0.000373119

m_t: = (m_t_1 * beta1) + g_t * (1 - beta1): 
       -0.00264607       -0.00407463       -0.00571505       -0.00538059       -0.00143407       -0.00198038       -0.00372573       -0.00616664       -0.00307676       -0.00274256        -0.0035249       -0.00485106       -0.00333794       -0.00330909       -0.00410701       -0.00475804
        0.00264607        0.00407463        0.00571505        0.00538059        0.00143407        0.00198038        0.00372573        0.00616664        0.00307676        0.00274256         0.0035249        0.00485106        0.00333794        0.00330909        0.00410701        0.00475804

v_t_1: 
       8.11548e-10       4.12796e-09        6.1871e-09       4.96992e-09       1.40002e-09       8.00926e-09       4.48048e-09       2.34843e-09       7.32943e-09       4.01597e-09       4.67477e-08       3.21994e-08       1.50841e-08       2.40794e-08       1.14931e-08       1.29524e-08
       8.11548e-10       4.12796e-09       6.18711e-09       4.96992e-09       1.40002e-09       8.00926e-09       4.48048e-09       2.34843e-09       7.32943e-09       4.01597e-09       4.67477e-08       3.21994e-08       1.50841e-08       2.40794e-08       1.14931e-08       1.29524e-08

g_t^2 * (1. - beta2(0.999))
       7.34317e-07        1.8661e-06       3.59535e-06       3.16818e-06       2.41286e-07        2.9064e-07       1.20509e-06       3.58421e-06       1.15276e-06       6.42963e-07       7.40465e-07        1.7677e-06       1.42871e-06       1.50279e-06       2.01088e-06       1.92276e-06
       7.34317e-07        1.8661e-06       3.59535e-06       3.16817e-06       2.41286e-07        2.9064e-07       1.20509e-06       3.58421e-06       1.15276e-06       6.42963e-07       7.40465e-07        1.7677e-06       1.42871e-06       1.50279e-06       2.01088e-06       1.92276e-06

v_t_1 * beta2:
       8.10737e-10       4.12383e-09       6.18092e-09       4.96495e-09       1.39862e-09       8.00125e-09         4.476e-09       2.34608e-09       7.32211e-09       4.01195e-09       4.67009e-08       3.21672e-08        1.5069e-08       2.40553e-08       1.14816e-08       1.29394e-08
       8.10737e-10       4.12383e-09       6.18092e-09       4.96495e-09       1.39862e-09       8.00125e-09         4.476e-09       2.34608e-09       7.32211e-09       4.01195e-09        4.6701e-08       3.21672e-08        1.5069e-08       2.40553e-08       1.14816e-08       1.29395e-08

vt = v_t_1*beta2 + g_t^2*(1-beta2): 
       7.35128e-07       1.87023e-06       3.60153e-06       3.17314e-06       2.42685e-07       2.98641e-07       1.20957e-06       3.58656e-06       1.16008e-06       6.46974e-07       7.87166e-07       1.79986e-06       1.44378e-06       1.52684e-06       2.02237e-06        1.9357e-06
       7.35127e-07       1.87022e-06       3.60153e-06       3.17314e-06       2.42684e-07       2.98641e-07       1.20957e-06       3.58656e-06       1.16008e-06       6.46975e-07       7.87166e-07       1.79986e-06       1.44378e-06       1.52684e-06       2.02237e-06       1.93569e-06

bias corrected m_t: /0.271
       -0.00976409        -0.0150355        -0.0210887        -0.0198546       -0.00529177       -0.00730768        -0.0137481        -0.0227551        -0.0113534        -0.0101201         -0.013007        -0.0179006        -0.0123171        -0.0122107         -0.015155        -0.0175574
        0.00976409         0.0150355         0.0210887         0.0198546        0.00529176        0.00730768         0.0137481         0.0227551         0.0113534         0.0101201          0.013007         0.0179006         0.0123171         0.0122107          0.015155         0.0175574

bias corrected v_t: /0.002997
       0.000245288       0.000624032        0.00120171        0.00105877       8.09759e-05       9.96467e-05       0.000403594        0.00119672       0.000387079       0.000215874       0.000262651       0.000600555       0.000481742       0.000509457       0.000674796       0.000645878
       0.000245288       0.000624032        0.00120171        0.00105877       8.09757e-05       9.96466e-05       0.000403594        0.00119672       0.000387079       0.000215874       0.000262651       0.000600555       0.000481742       0.000509457       0.000674796       0.000645877

sqrt(^v_t): 
         0.0156617         0.0249806         0.0346657         0.0325388        0.00899866        0.00998232         0.0200896         0.0345936         0.0196743         0.0146926         0.0162065         0.0245062         0.0219486         0.0225712         0.0259768         0.0254141
         0.0156617         0.0249806         0.0346657         0.0325388        0.00899865        0.00998231         0.0200896         0.0345936         0.0196743         0.0146927         0.0162065         0.0245062         0.0219486         0.0225712         0.0259768         0.0254141

m_epsilon: 
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08

sqrt(^v_t): + epsilon
         0.0156617         0.0249806         0.0346657         0.0325388        0.00899867        0.00998233         0.0200897         0.0345936         0.0196743         0.0146927         0.0162065         0.0245062         0.0219486         0.0225712         0.0259769         0.0254141
         0.0156617         0.0249806         0.0346657         0.0325388        0.00899866        0.00998232         0.0200896         0.0345936         0.0196743         0.0146927         0.0162065         0.0245062         0.0219486         0.0225712         0.0259769         0.0254141

^m_t/(sqrt(^v_t) + epsilon):
         -0.623439         -0.601888         -0.608345         -0.610182         -0.588061         -0.732062         -0.684336         -0.657785         -0.577064         -0.688789         -0.802578          -0.73045         -0.561179         -0.540985         -0.583404          -0.69085
          0.623439          0.601888          0.608345          0.610182          0.588061          0.732062          0.684336          0.657785          0.577064          0.688789          0.802578           0.73045          0.561179          0.540985          0.583404           0.69085

learning rate: 0.9
dw_Adam: 
         -0.561095         -0.541699         -0.547511         -0.549164         -0.529255         -0.658856         -0.615903         -0.592006         -0.519358          -0.61991          -0.72232         -0.657405         -0.505061         -0.486886         -0.525064         -0.621765
          0.561095          0.541699          0.547511          0.549164          0.529255          0.658856          0.615903          0.592006          0.519358           0.61991           0.72232          0.657405          0.505061          0.486886          0.525064          0.621765

        batch training cost: 393 milliseconds
............ accuracy for batch training: 0.835
............    losss for batch training: 0.831973
[------]Number of epoch: 3/50
......Info: 1 batches in this epoch
......... training for batch: 0/1
>>>: 200 samples in current batch.
----------------------------------------------------------
g_t: 
          0.228093          0.253303          0.285672          0.307657           0.21239          0.261305          0.296147          0.302962          0.222425          0.277447          0.317431          0.318966          0.217524           0.26252          0.300388          0.297862
         -0.228093         -0.253303         -0.285672         -0.307657          -0.21239         -0.261305         -0.296147         -0.302962         -0.222425         -0.277447         -0.317431         -0.318966         -0.217524          -0.26252         -0.300388         -0.297862

m_t_1: 
       -0.00264607       -0.00407463       -0.00571505       -0.00538059       -0.00143407       -0.00198038       -0.00372573       -0.00616664       -0.00307676       -0.00274256        -0.0035249       -0.00485106       -0.00333794       -0.00330909       -0.00410701       -0.00475804
        0.00264607        0.00407463        0.00571505        0.00538059        0.00143407        0.00198038        0.00372573        0.00616664        0.00307676        0.00274256         0.0035249        0.00485106        0.00333794        0.00330909        0.00410701        0.00475804

 1 - beta1: 0.1
m_tmp: 
         0.0228093         0.0253303         0.0285672         0.0307657          0.021239         0.0261305         0.0296147         0.0302962         0.0222425         0.0277447         0.0317431         0.0318966         0.0217524          0.026252         0.0300388         0.0297862
        -0.0228093        -0.0253303        -0.0285672        -0.0307657         -0.021239        -0.0261305        -0.0296147        -0.0302962        -0.0222425        -0.0277447        -0.0317431        -0.0318966        -0.0217524         -0.026252        -0.0300388        -0.0297862

m_t_1*beta1: 
       -0.00238146       -0.00366717       -0.00514354       -0.00484253       -0.00129066       -0.00178234       -0.00335316       -0.00554997       -0.00276908        -0.0024683       -0.00317241       -0.00436595       -0.00300414       -0.00297818       -0.00369631       -0.00428224
        0.00238146        0.00366717        0.00514354        0.00484253        0.00129066        0.00178234        0.00335316        0.00554998        0.00276908         0.0024683        0.00317241        0.00436595        0.00300414        0.00297818        0.00369631        0.00428224

m_t: = (m_t_1 * beta1) + g_t * (1 - beta1): 
         0.0204279         0.0216632         0.0234236         0.0259232         0.0199483         0.0243481         0.0262615         0.0247462         0.0194734         0.0252764         0.0285707         0.0275307         0.0187482         0.0232738         0.0263425         0.0255039
        -0.0204279        -0.0216632        -0.0234236        -0.0259232        -0.0199483        -0.0243481        -0.0262615        -0.0247462        -0.0194734        -0.0252764        -0.0285707        -0.0275307        -0.0187483        -0.0232738        -0.0263425        -0.0255039

v_t_1: 
       7.35128e-07       1.87023e-06       3.60153e-06       3.17314e-06       2.42685e-07       2.98641e-07       1.20957e-06       3.58656e-06       1.16008e-06       6.46974e-07       7.87166e-07       1.79986e-06       1.44378e-06       1.52684e-06       2.02237e-06        1.9357e-06
       7.35127e-07       1.87022e-06       3.60153e-06       3.17314e-06       2.42684e-07       2.98641e-07       1.20957e-06       3.58656e-06       1.16008e-06       6.46975e-07       7.87166e-07       1.79986e-06       1.44378e-06       1.52684e-06       2.02237e-06       1.93569e-06

g_t^2 * (1. - beta2(0.999))
       5.20266e-05       6.41626e-05       8.16083e-05       9.46531e-05       4.51093e-05       6.82802e-05       8.77029e-05        9.1786e-05       4.94728e-05       7.69768e-05       0.000100762        0.00010174       4.73167e-05       6.89166e-05       9.02332e-05       8.87216e-05
       5.20266e-05       6.41626e-05       8.16083e-05       9.46531e-05       4.51093e-05       6.82802e-05       8.77029e-05        9.1786e-05       4.94728e-05       7.69768e-05       0.000100762        0.00010174       4.73167e-05       6.89166e-05       9.02332e-05       8.87216e-05

v_t_1 * beta2:
       7.34393e-07       1.86836e-06       3.59793e-06       3.16997e-06       2.42442e-07       2.98343e-07       1.20836e-06       3.58297e-06       1.15892e-06       6.46327e-07       7.86379e-07       1.79806e-06       1.44234e-06       1.52532e-06       2.02034e-06       1.93376e-06
       7.34392e-07       1.86835e-06       3.59793e-06       3.16997e-06       2.42442e-07       2.98342e-07       1.20836e-06       3.58297e-06       1.15892e-06       6.46328e-07       7.86379e-07       1.79806e-06       1.44234e-06       1.52532e-06       2.02034e-06       1.93376e-06

vt = v_t_1*beta2 + g_t^2*(1-beta2): 
        5.2761e-05       6.60309e-05       8.52062e-05       9.78231e-05       4.53518e-05       6.85785e-05       8.89113e-05        9.5369e-05       5.06318e-05       7.76231e-05       0.000101549       0.000103538        4.8759e-05       7.04419e-05       9.22535e-05       9.06554e-05
        5.2761e-05       6.60309e-05       8.52063e-05       9.78231e-05       4.53518e-05       6.85785e-05       8.89113e-05        9.5369e-05       5.06318e-05       7.76231e-05       0.000101549       0.000103538        4.8759e-05       7.04419e-05       9.22535e-05       9.06554e-05

bias corrected m_t: /0.3439
         0.0594006         0.0629926         0.0681117         0.0753801         0.0580061            0.0708         0.0763638         0.0719576         0.0566252         0.0734992         0.0830785         0.0800543         0.0545166          0.067676         0.0765994         0.0741609
        -0.0594006        -0.0629926        -0.0681117        -0.0753801        -0.0580061           -0.0708        -0.0763638        -0.0719576        -0.0566252        -0.0734992        -0.0830785        -0.0800543        -0.0545166         -0.067676        -0.0765994        -0.0741609

bias corrected v_t: /0.003994
           0.01321         0.0165325         0.0213335         0.0244925          0.011355         0.0171704         0.0222612          0.023878         0.0126769         0.0194349         0.0254253         0.0259233         0.0122081         0.0176369          0.023098         0.0226979
           0.01321         0.0165325         0.0213335         0.0244925          0.011355         0.0171704         0.0222612          0.023878         0.0126769         0.0194349         0.0254253         0.0259233         0.0122081         0.0176369          0.023098         0.0226979

sqrt(^v_t): 
          0.114935          0.128579           0.14606          0.156501           0.10656          0.131036          0.149202          0.154525          0.112592          0.139409          0.159453          0.161007           0.11049          0.132804           0.15198          0.150658
          0.114935          0.128579           0.14606          0.156501           0.10656          0.131036          0.149202          0.154525          0.112592          0.139409          0.159453          0.161007           0.11049          0.132804           0.15198          0.150658

m_epsilon: 
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08

sqrt(^v_t): + epsilon
          0.114935          0.128579           0.14606          0.156501           0.10656          0.131036          0.149202          0.154525          0.112592          0.139409          0.159453          0.161007           0.11049          0.132804           0.15198          0.150658
          0.114935          0.128579           0.14606          0.156501           0.10656          0.131036          0.149202          0.154525          0.112592          0.139409          0.159453          0.161007           0.11049          0.132804           0.15198          0.150658

^m_t/(sqrt(^v_t) + epsilon):
          0.516819          0.489914          0.466327           0.48166          0.544353          0.540311          0.511816          0.465669          0.502924           0.52722          0.521021           0.49721          0.493407          0.509593          0.504009          0.492246
         -0.516819         -0.489914         -0.466327          -0.48166         -0.544353         -0.540311         -0.511816         -0.465669         -0.502924         -0.527219         -0.521021          -0.49721         -0.493407         -0.509593         -0.504009         -0.492246

learning rate: 0.9
dw_Adam: 
          0.465137          0.440923          0.419694          0.433494          0.489918           0.48628          0.460634          0.419102          0.452632          0.474498          0.468919          0.447489          0.444066          0.458634          0.453608          0.443022
         -0.465138         -0.440923         -0.419694         -0.433494         -0.489918          -0.48628         -0.460634         -0.419102         -0.452632         -0.474498         -0.468919         -0.447489         -0.444066         -0.458634         -0.453608         -0.443022

        batch training cost: 368 milliseconds
............ accuracy for batch training: 0.505
............    losss for batch training: 8.25119
[------]Number of epoch: 4/50
......Info: 1 batches in this epoch
......... training for batch: 0/1
>>>: 200 samples in current batch.
----------------------------------------------------------
g_t: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t_1: 
         0.0204279         0.0216632         0.0234236         0.0259232         0.0199483         0.0243481         0.0262615         0.0247462         0.0194734         0.0252764         0.0285707         0.0275307         0.0187482         0.0232738         0.0263425         0.0255039
        -0.0204279        -0.0216632        -0.0234236        -0.0259232        -0.0199483        -0.0243481        -0.0262615        -0.0247462        -0.0194734        -0.0252764        -0.0285707        -0.0275307        -0.0187483        -0.0232738        -0.0263425        -0.0255039

 1 - beta1: 0.1
m_tmp: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t_1*beta1: 
         0.0183851         0.0194968         0.0210813         0.0233309         0.0179535         0.0219133         0.0236354         0.0222716         0.0175261         0.0227487         0.0257136         0.0247776         0.0168734         0.0209464         0.0237083         0.0229535
        -0.0183851        -0.0194968        -0.0210813        -0.0233309        -0.0179535        -0.0219133        -0.0236354        -0.0222716        -0.0175261        -0.0227487        -0.0257136        -0.0247776        -0.0168734        -0.0209464        -0.0237083        -0.0229535

m_t: = (m_t_1 * beta1) + g_t * (1 - beta1): 
         0.0183851         0.0194968         0.0210813         0.0233309         0.0179535         0.0219133         0.0236354         0.0222716         0.0175261         0.0227487         0.0257136         0.0247776         0.0168734         0.0209464         0.0237083         0.0229535
        -0.0183851        -0.0194968        -0.0210813        -0.0233309        -0.0179535        -0.0219133        -0.0236354        -0.0222716        -0.0175261        -0.0227487        -0.0257136        -0.0247776        -0.0168734        -0.0209464        -0.0237083        -0.0229535

v_t_1: 
        5.2761e-05       6.60309e-05       8.52062e-05       9.78231e-05       4.53518e-05       6.85785e-05       8.89113e-05        9.5369e-05       5.06318e-05       7.76231e-05       0.000101549       0.000103538        4.8759e-05       7.04419e-05       9.22535e-05       9.06554e-05
        5.2761e-05       6.60309e-05       8.52063e-05       9.78231e-05       4.53518e-05       6.85785e-05       8.89113e-05        9.5369e-05       5.06318e-05       7.76231e-05       0.000101549       0.000103538        4.8759e-05       7.04419e-05       9.22535e-05       9.06554e-05

g_t^2 * (1. - beta2(0.999))
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

v_t_1 * beta2:
       5.27082e-05       6.59649e-05        8.5121e-05       9.77253e-05       4.53064e-05       6.85099e-05       8.88224e-05       9.52736e-05       5.05811e-05       7.75455e-05       0.000101447       0.000103434       4.87102e-05       7.03714e-05       9.21613e-05       9.05647e-05
       5.27082e-05       6.59649e-05        8.5121e-05       9.77253e-05       4.53064e-05       6.85099e-05       8.88224e-05       9.52736e-05       5.05811e-05       7.75455e-05       0.000101447       0.000103434       4.87102e-05       7.03714e-05       9.21613e-05       9.05647e-05

vt = v_t_1*beta2 + g_t^2*(1-beta2): 
       5.27082e-05       6.59649e-05        8.5121e-05       9.77253e-05       4.53064e-05       6.85099e-05       8.88224e-05       9.52736e-05       5.05811e-05       7.75455e-05       0.000101447       0.000103434       4.87102e-05       7.03714e-05       9.21613e-05       9.05647e-05
       5.27082e-05       6.59649e-05        8.5121e-05       9.77253e-05       4.53064e-05       6.85099e-05       8.88224e-05       9.52736e-05       5.05811e-05       7.75455e-05       0.000101447       0.000103434       4.87102e-05       7.03714e-05       9.21613e-05       9.05647e-05

bias corrected m_t: /0.40951
         0.0448953         0.0476102         0.0514792         0.0569727         0.0438413         0.0535111         0.0577162          0.054386         0.0427977         0.0555511         0.0627912         0.0605055         0.0412039         0.0511499         0.0578942         0.0560512
        -0.0448953        -0.0476102        -0.0514792        -0.0569727        -0.0438413        -0.0535111        -0.0577162         -0.054386        -0.0427977        -0.0555511        -0.0627912        -0.0605055        -0.0412039        -0.0511499        -0.0578943        -0.0560512

bias corrected v_t: /0.00499001
         0.0105627         0.0132194         0.0170583         0.0195842        0.00907942         0.0137294            0.0178         0.0190929         0.0101365         0.0155401         0.0203301         0.0207282        0.00976155         0.0141025         0.0184692         0.0181492
         0.0105627         0.0132194         0.0170583         0.0195842        0.00907942         0.0137294            0.0178         0.0190929         0.0101365         0.0155401         0.0203301         0.0207282        0.00976155         0.0141025         0.0184692         0.0181492

sqrt(^v_t): 
          0.102775          0.114976          0.130607          0.139943          0.095286          0.117173          0.133417          0.138177           0.10068           0.12466          0.142584          0.143973         0.0988006          0.118754          0.135901          0.134719
          0.102775          0.114976          0.130607          0.139943          0.095286          0.117173          0.133417          0.138177           0.10068           0.12466          0.142584          0.143973         0.0988006          0.118754          0.135901          0.134719

m_epsilon: 
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08

sqrt(^v_t): + epsilon
          0.102775          0.114976          0.130607          0.139944          0.095286          0.117173          0.133417          0.138177           0.10068           0.12466          0.142584          0.143973         0.0988006          0.118754          0.135901          0.134719
          0.102775          0.114976          0.130607          0.139944          0.095286          0.117173          0.133417          0.138177           0.10068           0.12466          0.142584          0.143973         0.0988006          0.118754          0.135901          0.134719

^m_t/(sqrt(^v_t) + epsilon):
           0.43683          0.414089          0.394153          0.407112          0.460102          0.456686          0.432601          0.393597          0.425086          0.445621          0.440382          0.420256          0.417041          0.430722          0.426002           0.41606
          -0.43683         -0.414089         -0.394153         -0.407112         -0.460103         -0.456686         -0.432601         -0.393597         -0.425086         -0.445621         -0.440382         -0.420256         -0.417042         -0.430722         -0.426002          -0.41606

learning rate: 0.9
dw_Adam: 
          0.393147           0.37268          0.354737          0.366401          0.414092          0.411017          0.389341          0.354237          0.382577          0.401059          0.396344           0.37823          0.375337           0.38765          0.383402          0.374454
         -0.393147          -0.37268         -0.354737         -0.366401         -0.414092         -0.411017         -0.389341         -0.354237         -0.382577         -0.401059         -0.396344          -0.37823         -0.375337          -0.38765         -0.383402         -0.374454

        batch training cost: 367 milliseconds
............ accuracy for batch training: 0
............    losss for batch training: 1.54357
[------]Number of epoch: 5/50
......Info: 1 batches in this epoch
......... training for batch: 0/1
>>>: 200 samples in current batch.
----------------------------------------------------------
g_t: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t_1: 
         0.0183851         0.0194968         0.0210813         0.0233309         0.0179535         0.0219133         0.0236354         0.0222716         0.0175261         0.0227487         0.0257136         0.0247776         0.0168734         0.0209464         0.0237083         0.0229535
        -0.0183851        -0.0194968        -0.0210813        -0.0233309        -0.0179535        -0.0219133        -0.0236354        -0.0222716        -0.0175261        -0.0227487        -0.0257136        -0.0247776        -0.0168734        -0.0209464        -0.0237083        -0.0229535

 1 - beta1: 0.1
m_tmp: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t_1*beta1: 
         0.0165466         0.0175472         0.0189731         0.0209978         0.0161581          0.019722         0.0212718         0.0200444         0.0157735         0.0204739         0.0231423         0.0222999         0.0151861         0.0188518         0.0213374         0.0206582
        -0.0165466        -0.0175472        -0.0189731        -0.0209978        -0.0161581         -0.019722        -0.0212718        -0.0200444        -0.0157735        -0.0204739        -0.0231423        -0.0222999        -0.0151861        -0.0188518        -0.0213374        -0.0206582

m_t: = (m_t_1 * beta1) + g_t * (1 - beta1): 
         0.0165466         0.0175472         0.0189731         0.0209978         0.0161581          0.019722         0.0212718         0.0200444         0.0157735         0.0204739         0.0231423         0.0222999         0.0151861         0.0188518         0.0213374         0.0206582
        -0.0165466        -0.0175472        -0.0189731        -0.0209978        -0.0161581         -0.019722        -0.0212718        -0.0200444        -0.0157735        -0.0204739        -0.0231423        -0.0222999        -0.0151861        -0.0188518        -0.0213374        -0.0206582

v_t_1: 
       5.27082e-05       6.59649e-05        8.5121e-05       9.77253e-05       4.53064e-05       6.85099e-05       8.88224e-05       9.52736e-05       5.05811e-05       7.75455e-05       0.000101447       0.000103434       4.87102e-05       7.03714e-05       9.21613e-05       9.05647e-05
       5.27082e-05       6.59649e-05        8.5121e-05       9.77253e-05       4.53064e-05       6.85099e-05       8.88224e-05       9.52736e-05       5.05811e-05       7.75455e-05       0.000101447       0.000103434       4.87102e-05       7.03714e-05       9.21613e-05       9.05647e-05

g_t^2 * (1. - beta2(0.999))
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

v_t_1 * beta2:
       5.26555e-05       6.58989e-05       8.50359e-05       9.76275e-05       4.52611e-05       6.84414e-05       8.87335e-05       9.51783e-05       5.05306e-05        7.7468e-05       0.000101346       0.000103331       4.86615e-05       7.03011e-05       9.20691e-05       9.04742e-05
       5.26555e-05       6.58989e-05       8.50359e-05       9.76275e-05       4.52611e-05       6.84414e-05       8.87335e-05       9.51783e-05       5.05306e-05       7.74679e-05       0.000101346       0.000103331       4.86615e-05       7.03011e-05       9.20691e-05       9.04742e-05

vt = v_t_1*beta2 + g_t^2*(1-beta2): 
       5.26555e-05       6.58989e-05       8.50359e-05       9.76275e-05       4.52611e-05       6.84414e-05       8.87335e-05       9.51783e-05       5.05306e-05        7.7468e-05       0.000101346       0.000103331       4.86615e-05       7.03011e-05       9.20691e-05       9.04742e-05
       5.26555e-05       6.58989e-05       8.50359e-05       9.76275e-05       4.52611e-05       6.84414e-05       8.87335e-05       9.51783e-05       5.05306e-05       7.74679e-05       0.000101346       0.000103331       4.86615e-05       7.03011e-05       9.20691e-05       9.04742e-05

bias corrected m_t: /0.468559
         0.0353138         0.0374492         0.0404925         0.0448136         0.0344847         0.0420907         0.0453984         0.0427789         0.0336638         0.0436954         0.0493903         0.0475924         0.0324102         0.0402335         0.0455384         0.0440888
        -0.0353138        -0.0374492        -0.0404925        -0.0448136        -0.0344847        -0.0420907        -0.0453984        -0.0427789        -0.0336638        -0.0436954        -0.0493903        -0.0475924        -0.0324102        -0.0402335        -0.0455384        -0.0440888

bias corrected v_t: /0.00598502
        0.00879788         0.0110106         0.0142081          0.016312         0.0075624         0.0114355         0.0148259         0.0159028        0.00844284         0.0129436         0.0169333         0.0172649        0.00813056         0.0117462         0.0153833         0.0151168
        0.00879788         0.0110106         0.0142081          0.016312         0.0075624         0.0114355         0.0148259         0.0159028        0.00844284         0.0129436         0.0169333         0.0172649        0.00813056         0.0117462         0.0153833         0.0151168

sqrt(^v_t): 
          0.093797          0.104932          0.119198          0.127718          0.086962          0.106937          0.121762          0.126106         0.0918849           0.11377          0.130128          0.131396         0.0901696           0.10838          0.124029           0.12295
          0.093797          0.104932          0.119198          0.127718          0.086962          0.106937          0.121762          0.126106         0.0918849           0.11377          0.130128          0.131396         0.0901696           0.10838          0.124029           0.12295

m_epsilon: 
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08

sqrt(^v_t): + epsilon
          0.093797          0.104932          0.119198          0.127718         0.0869621          0.106937          0.121762          0.126106         0.0918849           0.11377          0.130128          0.131396         0.0901696           0.10838          0.124029           0.12295
          0.093797          0.104932          0.119198          0.127718         0.0869621          0.106937          0.121762          0.126106         0.0918849           0.11377          0.130128          0.131396         0.0901696           0.10838          0.124029           0.12295

^m_t/(sqrt(^v_t) + epsilon):
          0.376491          0.356891          0.339709          0.350878          0.396549          0.393604          0.372846          0.339229          0.366369          0.384067          0.379552          0.362206          0.359436          0.371227          0.367159           0.35859
         -0.376491         -0.356892         -0.339709         -0.350878         -0.396549         -0.393604         -0.372846         -0.339229         -0.366369         -0.384067         -0.379552         -0.362206         -0.359436         -0.371227         -0.367159          -0.35859

learning rate: 0.9
dw_Adam: 
          0.338842          0.321202          0.305738           0.31579          0.356894          0.354244          0.335561          0.305306          0.329732          0.345661          0.341597          0.325986          0.323492          0.334104          0.330443          0.322731
         -0.338842         -0.321202         -0.305738          -0.31579         -0.356894         -0.354244         -0.335561         -0.305306         -0.329732         -0.345661         -0.341597         -0.325986         -0.323492         -0.334104         -0.330443         -0.322731

        batch training cost: 325 milliseconds
............ accuracy for batch training: 0
............    losss for batch training: 1.43879
[------]Number of epoch: 6/50
......Info: 1 batches in this epoch
......... training for batch: 0/1
>>>: 200 samples in current batch.
----------------------------------------------------------
g_t: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t_1: 
         0.0165466         0.0175472         0.0189731         0.0209978         0.0161581          0.019722         0.0212718         0.0200444         0.0157735         0.0204739         0.0231423         0.0222999         0.0151861         0.0188518         0.0213374         0.0206582
        -0.0165466        -0.0175472        -0.0189731        -0.0209978        -0.0161581         -0.019722        -0.0212718        -0.0200444        -0.0157735        -0.0204739        -0.0231423        -0.0222999        -0.0151861        -0.0188518        -0.0213374        -0.0206582

 1 - beta1: 0.1
m_tmp: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t_1*beta1: 
         0.0148919         0.0157924         0.0170758          0.018898         0.0145423         0.0177498         0.0191446           0.01804         0.0141961         0.0184265          0.020828         0.0200699         0.0136675         0.0169666         0.0192037         0.0185924
        -0.0148919        -0.0157924        -0.0170758         -0.018898        -0.0145423        -0.0177498        -0.0191446          -0.01804        -0.0141961        -0.0184265         -0.020828        -0.0200699        -0.0136675        -0.0169666        -0.0192037        -0.0185924

m_t: = (m_t_1 * beta1) + g_t * (1 - beta1): 
         0.0148919         0.0157924         0.0170758          0.018898         0.0145423         0.0177498         0.0191446           0.01804         0.0141961         0.0184265          0.020828         0.0200699         0.0136675         0.0169666         0.0192037         0.0185924
        -0.0148919        -0.0157924        -0.0170758         -0.018898        -0.0145423        -0.0177498        -0.0191446          -0.01804        -0.0141961        -0.0184265         -0.020828        -0.0200699        -0.0136675        -0.0169666        -0.0192037        -0.0185924

v_t_1: 
       5.26555e-05       6.58989e-05       8.50359e-05       9.76275e-05       4.52611e-05       6.84414e-05       8.87335e-05       9.51783e-05       5.05306e-05        7.7468e-05       0.000101346       0.000103331       4.86615e-05       7.03011e-05       9.20691e-05       9.04742e-05
       5.26555e-05       6.58989e-05       8.50359e-05       9.76275e-05       4.52611e-05       6.84414e-05       8.87335e-05       9.51783e-05       5.05306e-05       7.74679e-05       0.000101346       0.000103331       4.86615e-05       7.03011e-05       9.20691e-05       9.04742e-05

g_t^2 * (1. - beta2(0.999))
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

v_t_1 * beta2:
       5.26029e-05        6.5833e-05       8.49509e-05       9.75299e-05       4.52158e-05        6.8373e-05       8.86448e-05       9.50832e-05         5.048e-05       7.73905e-05       0.000101245       0.000103227       4.86129e-05       7.02308e-05        9.1977e-05       9.03837e-05
       5.26029e-05        6.5833e-05       8.49509e-05       9.75299e-05       4.52158e-05        6.8373e-05       8.86448e-05       9.50832e-05         5.048e-05       7.73905e-05       0.000101245       0.000103227       4.86129e-05       7.02308e-05        9.1977e-05       9.03837e-05

vt = v_t_1*beta2 + g_t^2*(1-beta2): 
       5.26029e-05        6.5833e-05       8.49509e-05       9.75299e-05       4.52158e-05        6.8373e-05       8.86448e-05       9.50832e-05         5.048e-05       7.73905e-05       0.000101245       0.000103227       4.86129e-05       7.02308e-05        9.1977e-05       9.03837e-05
       5.26029e-05        6.5833e-05       8.49509e-05       9.75299e-05       4.52158e-05        6.8373e-05       8.86448e-05       9.50832e-05         5.048e-05       7.73905e-05       0.000101245       0.000103227       4.86129e-05       7.02308e-05        9.1977e-05       9.03837e-05

bias corrected m_t: /0.521703
         0.0285448         0.0302709         0.0327309         0.0362237         0.0278747         0.0340228         0.0366964         0.0345791         0.0272111         0.0353199         0.0399232         0.0384699         0.0261978         0.0325215         0.0368096         0.0356378
        -0.0285448        -0.0302709        -0.0327309        -0.0362237        -0.0278747        -0.0340228        -0.0366964        -0.0345791        -0.0272111        -0.0353199        -0.0399232        -0.0384699        -0.0261978        -0.0325215        -0.0368096        -0.0356378

bias corrected v_t: /0.00697903
        0.00753727        0.00943297         0.0121723         0.0139747        0.00647881        0.00979691         0.0127016         0.0136241         0.0072331          0.011089          0.014507         0.0147911        0.00696556         0.0100631          0.013179         0.0129507
        0.00753727        0.00943297         0.0121723         0.0139747        0.00647881        0.00979691         0.0127016         0.0136241         0.0072331          0.011089          0.014507         0.0147911        0.00696556         0.0100631          0.013179         0.0129507

sqrt(^v_t): 
         0.0868174         0.0971235          0.110328          0.118215         0.0804911         0.0989793          0.112701          0.116722         0.0850476          0.105304          0.120445          0.121618         0.0834599          0.100315            0.1148          0.113801
         0.0868174         0.0971235          0.110328          0.118215         0.0804911         0.0989793          0.112701          0.116722         0.0850476          0.105304          0.120445          0.121618         0.0834599          0.100315            0.1148          0.113801

m_epsilon: 
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08

sqrt(^v_t): + epsilon
         0.0868175         0.0971235          0.110328          0.118215         0.0804911         0.0989793          0.112701          0.116722         0.0850476          0.105304          0.120445          0.121618         0.0834599          0.100315            0.1148          0.113801
         0.0868175         0.0971235          0.110328          0.118215         0.0804911         0.0989793          0.112701          0.116722         0.0850476          0.105304          0.120445          0.121618         0.0834599          0.100315            0.1148          0.113801

^m_t/(sqrt(^v_t) + epsilon):
          0.328791          0.311675          0.296669          0.306423          0.346308          0.343736          0.325608           0.29625          0.319951          0.335408          0.331464          0.316316          0.313897          0.324194          0.320641          0.313158
         -0.328791         -0.311675         -0.296669         -0.306423         -0.346308         -0.343736         -0.325608          -0.29625         -0.319951         -0.335408         -0.331464         -0.316316         -0.313897         -0.324194         -0.320641         -0.313158

learning rate: 0.9
dw_Adam: 
          0.295912          0.280507          0.267002          0.275781          0.311677          0.309362          0.293047          0.266625          0.287956          0.301867          0.298318          0.284685          0.282507          0.291775          0.288577          0.281842
         -0.295912         -0.280507         -0.267002         -0.275781         -0.311677         -0.309362         -0.293047         -0.266625         -0.287956         -0.301867         -0.298318         -0.284685         -0.282507         -0.291775         -0.288577         -0.281842

        batch training cost: 322 milliseconds
............ accuracy for batch training: 0
............    losss for batch training: 1.40273
[------]Number of epoch: 7/50
......Info: 1 batches in this epoch
......... training for batch: 0/1
>>>: 200 samples in current batch.
----------------------------------------------------------
g_t: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t_1: 
         0.0148919         0.0157924         0.0170758          0.018898         0.0145423         0.0177498         0.0191446           0.01804         0.0141961         0.0184265          0.020828         0.0200699         0.0136675         0.0169666         0.0192037         0.0185924
        -0.0148919        -0.0157924        -0.0170758         -0.018898        -0.0145423        -0.0177498        -0.0191446          -0.01804        -0.0141961        -0.0184265         -0.020828        -0.0200699        -0.0136675        -0.0169666        -0.0192037        -0.0185924

 1 - beta1: 0.1
m_tmp: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t_1*beta1: 
         0.0134027         0.0142132         0.0153682         0.0170082         0.0130881         0.0159748         0.0172302          0.016236         0.0127765         0.0165838         0.0187452         0.0180629         0.0123007         0.0152699         0.0172833         0.0167331
        -0.0134027        -0.0142132        -0.0153682        -0.0170082        -0.0130881        -0.0159748        -0.0172302         -0.016236        -0.0127765        -0.0165838        -0.0187452        -0.0180629        -0.0123007        -0.0152699        -0.0172833        -0.0167331

m_t: = (m_t_1 * beta1) + g_t * (1 - beta1): 
         0.0134027         0.0142132         0.0153682         0.0170082         0.0130881         0.0159748         0.0172302          0.016236         0.0127765         0.0165838         0.0187452         0.0180629         0.0123007         0.0152699         0.0172833         0.0167331
        -0.0134027        -0.0142132        -0.0153682        -0.0170082        -0.0130881        -0.0159748        -0.0172302         -0.016236        -0.0127765        -0.0165838        -0.0187452        -0.0180629        -0.0123007        -0.0152699        -0.0172833        -0.0167331

v_t_1: 
       5.26029e-05        6.5833e-05       8.49509e-05       9.75299e-05       4.52158e-05        6.8373e-05       8.86448e-05       9.50832e-05         5.048e-05       7.73905e-05       0.000101245       0.000103227       4.86129e-05       7.02308e-05        9.1977e-05       9.03837e-05
       5.26029e-05        6.5833e-05       8.49509e-05       9.75299e-05       4.52158e-05        6.8373e-05       8.86448e-05       9.50832e-05         5.048e-05       7.73905e-05       0.000101245       0.000103227       4.86129e-05       7.02308e-05        9.1977e-05       9.03837e-05

g_t^2 * (1. - beta2(0.999))
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

v_t_1 * beta2:
       5.25503e-05       6.57672e-05       8.48659e-05       9.74324e-05       4.51706e-05       6.83046e-05       8.85562e-05       9.49881e-05       5.04295e-05       7.73131e-05       0.000101143       0.000103124       4.85643e-05       7.01605e-05        9.1885e-05       9.02933e-05
       5.25503e-05       6.57672e-05       8.48659e-05       9.74324e-05       4.51706e-05       6.83046e-05       8.85562e-05       9.49881e-05       5.04295e-05       7.73131e-05       0.000101143       0.000103124       4.85643e-05       7.01605e-05        9.1885e-05       9.02933e-05

vt = v_t_1*beta2 + g_t^2*(1-beta2): 
       5.25503e-05       6.57672e-05       8.48659e-05       9.74324e-05       4.51706e-05       6.83046e-05       8.85562e-05       9.49881e-05       5.04295e-05       7.73131e-05       0.000101143       0.000103124       4.85643e-05       7.01605e-05        9.1885e-05       9.02933e-05
       5.25503e-05       6.57672e-05       8.48659e-05       9.74324e-05       4.51706e-05       6.83046e-05       8.85562e-05       9.49881e-05       5.04295e-05       7.73131e-05       0.000101143       0.000103124       4.85643e-05       7.01605e-05        9.1885e-05       9.02933e-05

bias corrected m_t: /0.569533
         0.0235328         0.0249559         0.0269839         0.0298635         0.0229804          0.028049         0.0302532         0.0285076         0.0224333         0.0291183         0.0329134         0.0317153         0.0215979         0.0268113         0.0303465         0.0293805
        -0.0235329        -0.0249559        -0.0269839        -0.0298635        -0.0229804         -0.028049        -0.0302532        -0.0285076        -0.0224333        -0.0291183        -0.0329134        -0.0317153        -0.0215979        -0.0268113        -0.0303465        -0.0293805

bias corrected v_t: /0.00797206
        0.00659181        0.00824972         0.0106454         0.0122217        0.00566612          0.008568         0.0111083         0.0119151        0.00632579        0.00969801         0.0126872         0.0129357        0.00609181        0.00880081         0.0115259         0.0113262
        0.00659181        0.00824971         0.0106454         0.0122217        0.00566612          0.008568         0.0111083         0.0119151        0.00632579        0.00969801         0.0126872         0.0129357        0.00609181        0.00880081         0.0115259         0.0113262

sqrt(^v_t): 
         0.0811899          0.090828          0.103177          0.110552         0.0752736         0.0925635          0.105396          0.109156         0.0795348         0.0984785          0.112638          0.113735         0.0780501         0.0938126          0.107359          0.106425
         0.0811899         0.0908279          0.103177          0.110552         0.0752736         0.0925635          0.105396          0.109156         0.0795348         0.0984785          0.112638          0.113735         0.0780501         0.0938126          0.107359          0.106425

m_epsilon: 
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08

sqrt(^v_t): + epsilon
           0.08119          0.090828          0.103177          0.110552         0.0752736         0.0925635          0.105396          0.109156         0.0795348         0.0984785          0.112638          0.113735         0.0780501         0.0938126          0.107359          0.106425
           0.08119         0.0908279          0.103177          0.110552         0.0752736         0.0925635          0.105396          0.109156         0.0795348         0.0984785          0.112638          0.113735         0.0780501         0.0938126          0.107359          0.106425

^m_t/(sqrt(^v_t) + epsilon):
          0.289849           0.27476          0.261531           0.27013          0.305291          0.303024          0.287043          0.261163          0.282056          0.295682          0.292206          0.278852          0.276719          0.285796          0.282665          0.276068
         -0.289849          -0.27476         -0.261531          -0.27013         -0.305291         -0.303024         -0.287043         -0.261163         -0.282056         -0.295682         -0.292206         -0.278852         -0.276719         -0.285796         -0.282665         -0.276068

learning rate: 0.9
dw_Adam: 
          0.260864          0.247284          0.235378          0.243117          0.274762          0.272722          0.258339          0.235046          0.253851          0.266114          0.262985          0.250967          0.249047          0.257217          0.254398          0.248461
         -0.260864         -0.247284         -0.235378         -0.243117         -0.274762         -0.272722         -0.258339         -0.235046         -0.253851         -0.266114         -0.262985         -0.250967         -0.249047         -0.257217         -0.254398         -0.248461

        batch training cost: 351 milliseconds
............ accuracy for batch training: 0
............    losss for batch training: 1.39132
[------]Number of epoch: 8/50
......Info: 1 batches in this epoch
......... training for batch: 0/1
>>>: 200 samples in current batch.
----------------------------------------------------------
g_t: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t_1: 
         0.0134027         0.0142132         0.0153682         0.0170082         0.0130881         0.0159748         0.0172302          0.016236         0.0127765         0.0165838         0.0187452         0.0180629         0.0123007         0.0152699         0.0172833         0.0167331
        -0.0134027        -0.0142132        -0.0153682        -0.0170082        -0.0130881        -0.0159748        -0.0172302         -0.016236        -0.0127765        -0.0165838        -0.0187452        -0.0180629        -0.0123007        -0.0152699        -0.0172833        -0.0167331

 1 - beta1: 0.1
m_tmp: 
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

m_t_1*beta1: 
         0.0120625         0.0127919         0.0138314         0.0153074         0.0117793         0.0143773         0.0155072         0.0146124         0.0114988         0.0149255         0.0168707         0.0162566         0.0110707         0.0137429          0.015555         0.0150598
        -0.0120625        -0.0127919        -0.0138314        -0.0153074        -0.0117793        -0.0143773        -0.0155072        -0.0146124        -0.0114988        -0.0149255        -0.0168707        -0.0162566        -0.0110707        -0.0137429         -0.015555        -0.0150598

m_t: = (m_t_1 * beta1) + g_t * (1 - beta1): 
         0.0120625         0.0127919         0.0138314         0.0153074         0.0117793         0.0143773         0.0155072         0.0146124         0.0114988         0.0149255         0.0168707         0.0162566         0.0110707         0.0137429          0.015555         0.0150598
        -0.0120625        -0.0127919        -0.0138314        -0.0153074        -0.0117793        -0.0143773        -0.0155072        -0.0146124        -0.0114988        -0.0149255        -0.0168707        -0.0162566        -0.0110707        -0.0137429         -0.015555        -0.0150598

v_t_1: 
       5.25503e-05       6.57672e-05       8.48659e-05       9.74324e-05       4.51706e-05       6.83046e-05       8.85562e-05       9.49881e-05       5.04295e-05       7.73131e-05       0.000101143       0.000103124       4.85643e-05       7.01605e-05        9.1885e-05       9.02933e-05
       5.25503e-05       6.57672e-05       8.48659e-05       9.74324e-05       4.51706e-05       6.83046e-05       8.85562e-05       9.49881e-05       5.04295e-05       7.73131e-05       0.000101143       0.000103124       4.85643e-05       7.01605e-05        9.1885e-05       9.02933e-05

g_t^2 * (1. - beta2(0.999))
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0
                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0

v_t_1 * beta2:
       5.24977e-05       6.57014e-05       8.47811e-05        9.7335e-05       4.51255e-05       6.82363e-05       8.84676e-05       9.48931e-05       5.03791e-05       7.72358e-05       0.000101042       0.000103021       4.85157e-05       7.00904e-05       9.17932e-05        9.0203e-05
       5.24977e-05       6.57014e-05       8.47811e-05        9.7335e-05       4.51255e-05       6.82363e-05       8.84676e-05       9.48931e-05       5.03791e-05       7.72358e-05       0.000101042       0.000103021       4.85157e-05       7.00904e-05       9.17932e-05        9.0203e-05

vt = v_t_1*beta2 + g_t^2*(1-beta2): 
       5.24977e-05       6.57014e-05       8.47811e-05        9.7335e-05       4.51255e-05       6.82363e-05       8.84676e-05       9.48931e-05       5.03791e-05       7.72358e-05       0.000101042       0.000103021       4.85157e-05       7.00904e-05       9.17932e-05        9.0203e-05
       5.24977e-05       6.57014e-05       8.47811e-05        9.7335e-05       4.51255e-05       6.82363e-05       8.84676e-05       9.48931e-05       5.03791e-05       7.72358e-05       0.000101042       0.000103021       4.85157e-05       7.00904e-05       9.17932e-05        9.0203e-05

bias corrected m_t: /0.61258
         0.0196912          0.020882          0.022579         0.0249884          0.019229         0.0234701         0.0253145         0.0238539         0.0187712         0.0243649         0.0275404         0.0265379         0.0180722         0.0224345         0.0253926         0.0245843
        -0.0196912         -0.020882         -0.022579        -0.0249884         -0.019229        -0.0234701        -0.0253145        -0.0238539        -0.0187712        -0.0243649        -0.0275404        -0.0265379        -0.0180722        -0.0224345        -0.0253926        -0.0245843

bias corrected v_t: /0.00896408
        0.00585645        0.00732941        0.00945786         0.0108583        0.00503403        0.00761219        0.00986912         0.0105859        0.00562011        0.00861614         0.0112719         0.0114926        0.00541223        0.00781902         0.0102401         0.0100627
        0.00585645        0.00732941        0.00945786         0.0108583        0.00503403        0.00761219        0.00986912         0.0105859        0.00562011        0.00861614         0.0112719         0.0114926        0.00541223        0.00781902         0.0102401         0.0100627

sqrt(^v_t): 
         0.0765274          0.085612         0.0972515          0.104203         0.0709509         0.0872479         0.0993434          0.102888         0.0749674         0.0928231          0.106169          0.107204         0.0735679         0.0884252          0.101193          0.100313
         0.0765274          0.085612         0.0972515          0.104203         0.0709509         0.0872479         0.0993434          0.102888         0.0749674         0.0928231          0.106169          0.107204         0.0735679         0.0884252          0.101193          0.100313

m_epsilon: 
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08
             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08             1e-08

sqrt(^v_t): + epsilon
         0.0765275          0.085612         0.0972515          0.104203         0.0709509         0.0872479         0.0993434          0.102888         0.0749674         0.0928232          0.106169          0.107204         0.0735679         0.0884252          0.101193          0.100313
         0.0765275          0.085612         0.0972515          0.104203         0.0709509         0.0872479         0.0993434          0.102888         0.0749674         0.0928231          0.106169          0.107204         0.0735679         0.0884252          0.101193          0.100313

^m_t/(sqrt(^v_t) + epsilon):
           0.25731          0.243914          0.232171          0.239805          0.271018          0.269005          0.254818          0.231843          0.250392          0.262488          0.259402          0.247547          0.245653          0.253712          0.250931          0.245075
          -0.25731         -0.243914         -0.232171         -0.239805         -0.271018         -0.269005         -0.254818         -0.231843         -0.250392         -0.262488         -0.259402         -0.247547         -0.245653         -0.253712         -0.250932         -0.245075

learning rate: 0.9
dw_Adam: 
          0.231579          0.219523          0.208954          0.215824          0.243916          0.242105          0.229336          0.208659          0.225352          0.236239          0.233461          0.222792          0.221088          0.228341          0.225838          0.220568
         -0.231579         -0.219523         -0.208954         -0.215824         -0.243916         -0.242105         -0.229336         -0.208659         -0.225352         -0.236239         -0.233461         -0.222792         -0.221088         -0.228341         -0.225838         -0.220568

